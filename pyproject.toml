[tool.poetry]
name = "llama_autointerp"
version = "0.1.0"
description = "Autointerp for local llama models with llama-cpp."
authors = ["Aidan Ewart <aidanprattewart@gmail.com>"]
readme = "README.md"

[tool.poetry.dependencies]
python = ">=3.10, <3.12"
transformers = "^4.35.2"
torch = "^2.1.1"
neuron-explainer = {git = "https://github.com/openai/automated-interpretability.git", subdirectory = "neuron-explainer"}
llama-cpp-python = "^0.2.20"


[tool.poetry.group.dev.dependencies]
pytest = "^7.4.3"
pyright = "^1.1.338"

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"
